{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: For each sentence identify other similar sentences**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import heapq\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import xlrd\n",
    "# import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "INPUT_FILE = \"Interview_Identify_similar_sentences.xlsx\"\n",
    "LEXICAL_OUTPUT_FILE = \"Interview_Identify_similar_sentences_output.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9534, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = os.path.join(DATA_DIR, INPUT_FILE)\n",
    "df = pd.read_excel(input_path, header = None, names=['sentence'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an additional ID column\n",
    "df.insert(0, 'sentenceId', np.arange(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>3969</td>\n",
       "      <td>How do you know who viewed you video on Instag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9507</th>\n",
       "      <td>9507</td>\n",
       "      <td>How do I stop caring for people who don't real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279</th>\n",
       "      <td>9279</td>\n",
       "      <td>What‚Äôs your biggest regret that you have in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9056</th>\n",
       "      <td>9056</td>\n",
       "      <td>What is a hard disk? What function does it hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>5318</td>\n",
       "      <td>What knowledge should one have to create an op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2164</td>\n",
       "      <td>How can we know that the Illuminati is real?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>8202</td>\n",
       "      <td>How do you have the motvitation to exercise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>2988</td>\n",
       "      <td>Do you have any tips for coping with anxiety?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>6538</td>\n",
       "      <td>Can a boy join the Indian armed forces after a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>3335</td>\n",
       "      <td>How can I get 99 percentile and above in CAT 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentenceId                                           sentence\n",
       "3969        3969  How do you know who viewed you video on Instag...\n",
       "9507        9507  How do I stop caring for people who don't real...\n",
       "9279        9279  What‚Äôs your biggest regret that you have in ...\n",
       "9056        9056  What is a hard disk? What function does it hav...\n",
       "5318        5318  What knowledge should one have to create an op...\n",
       "2164        2164       How can we know that the Illuminati is real?\n",
       "8202        8202       How do you have the motvitation to exercise?\n",
       "2988        2988      Do you have any tips for coping with anxiety?\n",
       "6538        6538  Can a boy join the Indian armed forces after a...\n",
       "3335        3335  How can I get 99 percentile and above in CAT 2..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '¥', '©', '¬', 'º', 'Ä', 'Ç', 'Ô', 'ì', 'ò', 'ô', 'ù', 'ú', 'ü', 'π', '‚', '†', '√']\n"
     ]
    }
   ],
   "source": [
    "# List all the characters in entire data\n",
    "print(sorted(set(' '.join(df['sentence'].values.tolist()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform below steps for cleaning\n",
    "\n",
    "- **Add Extra space before and after .,!?**\n",
    "\n",
    "- **Except for alphabets(lower & capital), numbers, .,!'? replace other characters with spaces**\n",
    "\n",
    "- **Remove extra and trailing spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # add extra space before and after .,!?\n",
    "    pattern = r\"([.,!?])\"\n",
    "    text = re.sub(pattern, r\" \\1 \", text)\n",
    "    # replace extra characters with space\n",
    "    pattern = r\"[^a-zA-Z0-9.,!'?]+\"\n",
    "    text = re.sub(pattern, \" \", text)\n",
    "    # Remove extra spaces\n",
    "    pattern = r\"\\s+\"\n",
    "    text = re.sub(pattern, \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What does Balaji Vishwanathan think about Modi's new currency Idea ?\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample Test\n",
    "clean_text(\"What does Balaji Vishwanathan think about Modi's new currency Idea?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8101</th>\n",
       "      <td>8101</td>\n",
       "      <td>What is the biggest/most important decision yo...</td>\n",
       "      <td>What is the biggest most important decision yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5648</th>\n",
       "      <td>5648</td>\n",
       "      <td>Where should I start learning C?</td>\n",
       "      <td>Where should I start learning C ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>How do I motivate myself to wake up early?</td>\n",
       "      <td>How do I motivate myself to wake up early ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1471</td>\n",
       "      <td>What is the best age to tell your kid that he'...</td>\n",
       "      <td>What is the best age to tell your kid that he'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>1205</td>\n",
       "      <td>What are the reasons why wars happen?</td>\n",
       "      <td>What are the reasons why wars happen ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentenceId                                           sentence  \\\n",
       "8101        8101  What is the biggest/most important decision yo...   \n",
       "5648        5648                   Where should I start learning C?   \n",
       "401          401         How do I motivate myself to wake up early?   \n",
       "1471        1471  What is the best age to tell your kid that he'...   \n",
       "1205        1205              What are the reasons why wars happen?   \n",
       "\n",
       "                                         clean_sentence  \n",
       "8101  What is the biggest most important decision yo...  \n",
       "5648                  Where should I start learning C ?  \n",
       "401         How do I motivate myself to wake up early ?  \n",
       "1471  What is the best age to tell your kid that he'...  \n",
       "1205             What are the reasons why wars happen ?  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply preprocess steps on all records\n",
    "df['clean_sentence'] = df['sentence'].apply(clean_text)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-Tagging\n",
    "Now the text is clean of special characters and unnecessary punctuations. We move to the next phase and obtain the **pos tags** for every sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tags(text):\n",
    "    return pos_tag(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What', 'WP'),\n",
       " ('does', 'VBZ'),\n",
       " ('Balaji', 'NNP'),\n",
       " ('Vishwanathan', 'NNP'),\n",
       " ('think', 'VBP'),\n",
       " ('about', 'IN'),\n",
       " (\"Modi's\", 'NNP'),\n",
       " ('new', 'JJ'),\n",
       " ('currency', 'NN'),\n",
       " ('Idea', 'NNP'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample test\n",
    "get_pos_tags(clean_text(\"What does Balaji Vishwanathan think about Modi's new currency Idea?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once we obtain the POS-tag for each word in the sentence, we will append that tag to the word**\n",
    "\n",
    "Once the tags are obtained we will convert all the words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_pos_tags(text):\n",
    "    pos_tagged_list = get_pos_tags(text)\n",
    "    tag_map = {}\n",
    "    tag_map['N'] = wn.NOUN\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    \n",
    "    lemma_text = ' '.join([lemmatizer.lemmatize(word.lower(), tag_map.get(tag[0], wn.NOUN)) for word, tag in pos_tagged_list])\n",
    "    return lemma_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what do balaji vishwanathan think about modi's new currency idea ?\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample test\n",
    "append_pos_tags(clean_text(\"What does Balaji Vishwanathan think about Modi's new currency Idea?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>tagged_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>1974</td>\n",
       "      <td>When will I know I found the one?</td>\n",
       "      <td>When will I know I found the one ?</td>\n",
       "      <td>when will i know i find the one ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>7176</td>\n",
       "      <td>Why were the polls so inaccurate in the 2016 e...</td>\n",
       "      <td>Why were the polls so inaccurate in the 2016 e...</td>\n",
       "      <td>why be the poll so inaccurate in the 2016 elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>6505</td>\n",
       "      <td>What common mistake do people make when choosi...</td>\n",
       "      <td>What common mistake do people make when choosi...</td>\n",
       "      <td>what common mistake do people make when choose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>3105</td>\n",
       "      <td>What is the best earphones available under Rs....</td>\n",
       "      <td>What is the best earphones available under Rs ...</td>\n",
       "      <td>what be the best earphone available under r . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>6937</td>\n",
       "      <td>How much does it cost (yearly) to do a MS in C...</td>\n",
       "      <td>How much does it cost yearly to do a MS in Can...</td>\n",
       "      <td>how much do it cost yearly to do a m in canada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentenceId                                           sentence  \\\n",
       "1974        1974                  When will I know I found the one?   \n",
       "7176        7176  Why were the polls so inaccurate in the 2016 e...   \n",
       "6505        6505  What common mistake do people make when choosi...   \n",
       "3105        3105  What is the best earphones available under Rs....   \n",
       "6937        6937  How much does it cost (yearly) to do a MS in C...   \n",
       "\n",
       "                                         clean_sentence  \\\n",
       "1974                 When will I know I found the one ?   \n",
       "7176  Why were the polls so inaccurate in the 2016 e...   \n",
       "6505  What common mistake do people make when choosi...   \n",
       "3105  What is the best earphones available under Rs ...   \n",
       "6937  How much does it cost yearly to do a MS in Can...   \n",
       "\n",
       "                                        tagged_sentence  \n",
       "1974                  when will i know i find the one ?  \n",
       "7176  why be the poll so inaccurate in the 2016 elec...  \n",
       "6505  what common mistake do people make when choose...  \n",
       "3105  what be the best earphone available under r . ...  \n",
       "6937  how much do it cost yearly to do a m in canada...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this transformation on all the records in data\n",
    "df['tagged_sentence'] = df['clean_sentence'].apply(append_pos_tags)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "\n",
    "Convert the text into Tf-Idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.95, ngram_range=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9534, 2990)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat = vectorizer.fit_transform(df['tagged_sentence'])\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if we have any rows with all values as zeros\n",
    "# This situation might occur if any sentence only has infrequent words which we have dropped during vectorization\n",
    "np.where(~tfidf_mat.todense().any(axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pkl\", \"wb+\") as fp:\n",
    "    pickle.dump(file=fp, obj=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We know that the Tf-Idf representation is sparse, let us use some dimensionality reduction technique to reduce the dimensions and obtain a dense representation of data**\n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "- Use PCA to reduce the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca_vectors = pca.fit_transform(tfidf_mat.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9534, 1256)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due to memory constraints Fixing the number of components to 250. Since the Frobenius norm is high we can increase the components count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pca_vectors.pkl\", \"wb+\") as fp:\n",
    "    pickle.dump(file=fp, obj=pca_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pca_vectors.pkl\", \"rb\") as fp:\n",
    "    pca_vectors = pickle.load(file=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Calculation\n",
    "\n",
    "- I'll be using cosine similarity as my metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    return np.dot(A, B) / (np.linalg.norm(A)*np.linalg.norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code calculates the similarity between each records and every other record.\n",
    "# But for each input sentence we require only top 3. So no point in wasting memory for the rest\n",
    "\n",
    "\n",
    "# similarity_matrix = cdist(pca_matrix, pca_matrix, cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I'll be implementing a Heap based solution where in for each sentence we maintain a heap to keep track of top-3 similar sentences while iterating over the whole dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_results(results, index, inner_index, score, TOP_K):\n",
    "    heap = results[index]\n",
    "    # Pushing the similarity score and inner_index index of the sentence \n",
    "    heapq.heappush(heap, (score, inner_index))\n",
    "    # Since we only need to store K=3 similar sentences, pop other sentences with lesser scores\n",
    "    if len(heap) > TOP_K:\n",
    "        _ = heapq.heappop(heap)\n",
    "    results[index] = heap\n",
    "    return results\n",
    "\n",
    "def get_top_k_similar_sentences(matrix, func = cosine_similarity, TOP_K = 3):\n",
    "    results = [[] for _ in range(matrix.shape[0])]\n",
    "    # Iterating over all sentences\n",
    "    for index in tqdm(range(matrix.shape[0])):\n",
    "        # Each Input sentece in PCA based representation\n",
    "        vector = matrix[index]\n",
    "        # Initializing empty list to keep track of similar sentences\n",
    "        heap = []\n",
    "        # Iterating over rest of the sentences\n",
    "        for inner_index in range(index, matrix.shape[0]):\n",
    "            # checking if outer loop index and inner loop index are not equal\n",
    "            if index != inner_index:\n",
    "                # calculate cosine similarity between two vectors\n",
    "                score = func(vector, matrix[inner_index])\n",
    "                # Adding similarity scores to the results\n",
    "                results = add_to_results(results, index, inner_index, score, TOP_K)\n",
    "                # Since cosine similarity score is symmetric \n",
    "                results = add_to_results(results, inner_index, index, score, TOP_K)\n",
    "        # Sorting the array in descending order before storing into results\n",
    "        results[index] = sorted(results[index], key=lambda x : x[0], reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9534/9534 [5:38:57<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 3\n",
    "results = get_top_k_similar_sentences(matrix=pca_vectors, \n",
    "                                     func=cosine_similarity, \n",
    "                                     TOP_K=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.pkl\", \"wb+\") as fp:\n",
    "    pickle.dump(file=fp, obj=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.pkl\", \"rb\") as fp:\n",
    "    results = pickle.load(file=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_results(df, results, index):\n",
    "    print(\"Input: {}) {}\".format(index, df.loc[index, \"sentence\"]))\n",
    "    print(\"\\nSimilar Sentences: \")\n",
    "    for i, tup in enumerate(results[index]):\n",
    "        if tup[0] > 0.5:\n",
    "            print(\"{}) {} {:.2f}\".format(tup[1], df.loc[tup[1], \"sentence\"], tup[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 8631) Is downloading from torrent is still illegal in India?\n",
      "\n",
      "Similar Sentences: \n",
      "7568) Is downloading from torrent is still illegal in India? 1.00\n",
      "3974) Is downloading from torrent illegal in India? 0.91\n",
      "5363) Is downloading from torrent illegal in India? 0.91\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 1460) Which is the coldest country?\n",
      "\n",
      "Similar Sentences: \n",
      "1797) Which is the coldest country? 1.00\n",
      "2008) Which is the coldest country? 1.00\n",
      "3716) Which is the coldest country? 1.00\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 3982) Can any state secede from United States?\n",
      "\n",
      "Similar Sentences: \n",
      "3143) Can any state secede from United States? 1.00\n",
      "1096) Can any state secede from United States? 1.00\n",
      "1839) Can any state secede from United States? 1.00\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 9009) What is your favourite poem and why?\n",
      "\n",
      "Similar Sentences: \n",
      "5939) What is your favourite poem and why? 1.00\n",
      "7848) Which is your favourite poem and why? 0.93\n",
      "8292) Which is your favourite poem and why? 0.93\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 7644) Which laptop or notebook can I buy under 20k?\n",
      "\n",
      "Similar Sentences: \n",
      "5028) Which laptop or notebook can I buy under 20k? 1.00\n",
      "6712) Which laptop or notebook can I buy under 20k? 1.00\n",
      "9067) Which laptop or notebook can I buy under 20k? 1.00\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 1666) What are the best hotels in Rajasthan?\n",
      "\n",
      "Similar Sentences: \n",
      "1596) What are the best hotels in Rajasthan? 1.00\n",
      "6363) What is the best hotel in Rajasthan? 1.00\n",
      "6833) What are the best hotels in Rajasthan? 1.00\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 2579) Has there ever been a conflict of orbital paths between two satellites that were going to crash into each other?\n",
      "\n",
      "Similar Sentences: \n",
      "5704) Why don't satellites crash into each other? 0.63\n",
      "7346) Why don't satellites crash into each other? 0.63\n",
      "8544) Why don't satellites crash into each other? 0.63\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 3160) What is the First Amendment's purpose?\n",
      "\n",
      "Similar Sentences: \n",
      "8067) What is the First Amendment's purpose? 1.00\n",
      "3300) What is the First Amendment? 0.79\n",
      "1661) What is the First Amendment? 0.79\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 3944) Why do we always see the same side of the Moon from Earth?\n",
      "\n",
      "Similar Sentences: \n",
      "1959) Why do we always see the same side of the Moon from Earth? 1.00\n",
      "1448) Why do we always see the same side of the Moon from Earth? 1.00\n",
      "4095) Why do we always see the same side of the Moon from Earth? 1.00\n",
      "\n",
      "=====================================\n",
      "\n",
      "Input: 3666) When I get paid by Paytm by someone how do I transfer it to my bank account?\n",
      "\n",
      "Similar Sentences: \n",
      "918) How do I transfer Paytm balance to bank account? 0.62\n",
      "1144) How do I transfer Paytm balance to bank account? 0.62\n",
      "8433) How do I transfer Paytm balance to bank account? 0.62\n",
      "\n",
      "=====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    index = np.random.randint(9533)\n",
    "    print_sample_results(df, results, index)\n",
    "    print(\"\\n=====================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending results to dataframe in required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_indices = [0 for _ in range(len(results))]\n",
    "similar_sentence_scores = [0 for _ in range(len(results))]\n",
    "for key, row_results in enumerate(results):\n",
    "    similar_indices[key] = ', '.join([str(row_result[1]) for row_result in row_results if row_result[0] >= 0.5])\n",
    "    similar_sentence_scores[key] = ', '.join([\"{:.2f}\".format(row_result[0]) for row_result in row_results if row_result[0] >= 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Similar Sentences'] = similar_indices\n",
    "df['Similarity Score'] = similar_sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_similar'] = df['Similarity Score'] != ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing results back to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(DATA_DIR, LEXICAL_OUTPUT_FILE))\n",
    "df.loc[df['has_similar'], ['sentenceId', 'sentence', 'Similar Sentences', 'Similarity Score']].to_excel(writer, sheet_name=\"Sentence Similarities\", index=False)\n",
    "df.loc[~df['has_similar'], ['sentenceId', 'sentence']].to_excel(writer, sheet_name=\"No Similar Sentence\", index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
